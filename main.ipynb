{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fob6uNclW3-s",
        "outputId": "ac1f67d5-9f20-413f-f1a7-3ce7eb7a72e7"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "# path = './drive/MyDrive/NLP-Twitter-Sentiment-Analysis/'\n",
        "\n",
        "path = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QWnzwu-TW0y-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from rnnlibrary import rnn_model\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_PavZCgsW0y_",
        "outputId": "6fe93a54-a7de-4cf3-cc98-6a355ed70eaf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75675</th>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75676</th>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75677</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75678</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75679</th>\n",
              "      <td>Neutral</td>\n",
              "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment                                            context\n",
              "75675  Irrelevant  ⭐️ Toronto is the arts and culture capital of ...\n",
              "75676  Irrelevant  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...\n",
              "75677    Positive  Today sucked so it’s time to drink wine n play...\n",
              "75678    Positive  Bought a fraction of Microsoft today. Small wins.\n",
              "75679     Neutral  Johnson & Johnson to stop selling talc baby po..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = pd.read_csv(path + 'Datas/twitter_training.csv')\n",
        "validation_data = pd.read_csv(path +'Datas/twitter_validation.csv')\n",
        "\n",
        "training_data.columns = ['id', 'entity', 'sentiment', 'context']\n",
        "validation_data.columns = ['id', 'entity', 'sentiment', 'context']\n",
        "\n",
        "df = pd.concat(\n",
        "    [training_data, validation_data],\n",
        "    ignore_index=True,\n",
        ")\n",
        "\n",
        "df = df.drop(['id', 'entity'], axis=1)\n",
        "\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XV-D7UZW0zA",
        "outputId": "2119cdb5-0f8f-4ada-8c92-1a3852b2bda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 75680 entries, 0 to 75679\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   sentiment  75680 non-null  object\n",
            " 1   context    74994 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aGgN9eJ0W0zB"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "RBSRu2_HW0zE",
        "outputId": "8b895434-f56c-43e7-be34-3430af1dc0b6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "colors = [\n",
        "    '#FF5733', '#088395', '#66FF33', '#D2DE32'\n",
        "]\n",
        "\n",
        "def plot_sentiment(data):\n",
        "    explodes = ([0.02 for _ in range(len(set(data['sentiment'])))])\n",
        "    value_counts = data['sentiment'].value_counts()\n",
        "    labels = value_counts.index\n",
        "    values = value_counts.values\n",
        "\n",
        "    plt.pie(values, labels=labels, colors=colors, autopct='%1.1f%%', explode=explodes)\n",
        "    plt.show()\n",
        "\n",
        "plot_sentiment(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "McD-8wz6W0zE"
      },
      "outputs": [],
      "source": [
        "sentiment_values = df['sentiment'].value_counts().index\n",
        "\n",
        "def update_sentiment_values(sentiment):\n",
        "\n",
        "    if sentiment == sentiment_values[0]:\n",
        "        return 0\n",
        "    elif sentiment == sentiment_values[1]:\n",
        "        return 1\n",
        "    elif sentiment == sentiment_values[2]:\n",
        "        return 2\n",
        "    elif sentiment == sentiment_values[3]:\n",
        "        return 3\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "df['sentiment'] = df['sentiment'].apply(update_sentiment_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxXcx_zSXke2",
        "outputId": "f8379e55-c6a8-4e0b-ac3e-5f48e1d636f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\90530\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bxXMkK4rW0zF"
      },
      "outputs": [],
      "source": [
        "eng_stopwords = stopwords.words('english')\n",
        "\n",
        "sample_text = df['context'][75675]\n",
        "sample_text = re.sub('[^a-zA-Z]', ' ', sample_text)\n",
        "sample_text = [word.lower() for word in sample_text.split() if word.lower() not in eng_stopwords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "N4gp7XQqW0zF",
        "outputId": "7fe29b93-d2e6-44f2-e7bc-27e72fa03276"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'⭐️ Toronto is the arts and culture capital of Canada, it’s no wonder! If you want to start planning, be sure to check out our GTA Real Estate market report for Fall 2020, it has all the info you need to finally make a move! blog.remax.ca/toronto-housin… twitter.com/kevinyoufool/s…'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# original text\n",
        "df['context'][75675]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ChB7EGuuW0zG",
        "outputId": "507a9d52-9203-4c51-cb7a-cced1cd77ee3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'toronto arts culture capital canada wonder want start planning sure check gta real estate market report fall info need finally make move blog remax ca toronto housin twitter com kevinyoufool'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# after preprocessing\n",
        "' '.join(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OO-HEXUvW0zG",
        "outputId": "e62f4b37-c964-4b9f-cf63-28c8bb04f43a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting into borderlands and i can murder y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            context\n",
              "0          1  I am coming to the borders and I will kill you...\n",
              "1          1  im getting on borderlands and i will kill you ...\n",
              "2          1  im coming on borderlands and i will murder you...\n",
              "3          1  im getting on borderlands 2 and i will murder ...\n",
              "4          1  im getting into borderlands and i can murder y..."
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ccZ5ZcjfW0zH",
        "outputId": "397ec2ec-bcd0-4a0c-c667-b731214dd0e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>coming borders kill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting borderlands kill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>im coming borderlands murder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting borderlands murder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>im getting borderlands murder</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                        context\n",
              "0          1            coming borders kill\n",
              "1          1    im getting borderlands kill\n",
              "2          1   im coming borderlands murder\n",
              "3          1  im getting borderlands murder\n",
              "4          1  im getting borderlands murder"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_stopwords = stopwords.words('english')\n",
        "\n",
        "def preprocessing_context(context):\n",
        "    context = re.sub('[^a-zA-Z]', ' ' ,context)\n",
        "    context = [word.lower() for word in context.split() if word.lower() not in eng_stopwords]\n",
        "    return ' '.join(context)\n",
        "\n",
        "df['context'] = df['context'].apply(preprocessing_context)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xMedvdgfW0zH"
      },
      "outputs": [],
      "source": [
        "y = df['sentiment']\n",
        "X = df['context']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_a-XtM7QW0zH"
      },
      "outputs": [],
      "source": [
        "def word_tokenizer(n_words):\n",
        "\n",
        "    tokenizer = Tokenizer(n_words)\n",
        "\n",
        "    tokenizer.fit_on_texts(X)\n",
        "\n",
        "    X_train_token = tokenizer.texts_to_sequences(X_train)\n",
        "    X_test_token = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "    num_tokens = np.array([len(token) for token in X_train_token + X_test_token])\n",
        "\n",
        "    max_token = int(num_tokens.mean()) + 2 * int(num_tokens.std())\n",
        "\n",
        "    X_train_tokenized_pad = pad_sequences(X_train_token, maxlen=max_token)\n",
        "    X_test_tokenized_pad = pad_sequences(X_test_token, maxlen=max_token)\n",
        "\n",
        "    y_train_categorical = to_categorical(y_train)\n",
        "    y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "    return X_train_tokenized_pad, X_test_tokenized_pad, y_train_categorical, y_test_categorical, num_tokens, max_token, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7gub7dvdLMGA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of uniq words: 29645\n"
          ]
        }
      ],
      "source": [
        "num_words = len(set(' '.join([a for a in X]).split(' ')))\n",
        "\n",
        "print(f\"Total number of uniq words: {num_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    X_train_tokenized_pad, X_test_tokenized_pad, y_train_categorical, y_test_categorical, num_tokens, max_token, tokenizer\n",
        ") = word_tokenizer(num_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOuh-5I1Dxyn",
        "outputId": "a414a5d2-0e4a-42a0-e752-dfb785ce722f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max token 27\n",
            "std 8.037868368226333\n",
            "mean 11.26220764327813\n"
          ]
        }
      ],
      "source": [
        "print(\"max token\", max_token)\n",
        "print('std', num_tokens.std())\n",
        "print('mean', num_tokens.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGFBdKcvDQfi",
        "outputId": "ef960e62-d5f2-486c-d206-c0bb2f53cc82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape : (59995, 27)\n",
            "X_test shape : (14999, 27)\n",
            "y_train shape : (59995, 4)\n",
            "y_test shape : (14999, 4)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train shape : {X_train_tokenized_pad.shape}\")\n",
        "print(f\"X_test shape : {X_test_tokenized_pad.shape}\")\n",
        "print(f\"y_train shape : {y_train_categorical.shape}\")\n",
        "print(f\"y_test shape : {y_test_categorical.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6df835AlW0zJ"
      },
      "outputs": [],
      "source": [
        "glove_path = path + 'Glove/glove.6B.100d.txt'\n",
        "\n",
        "glove_embedding_matrix = {}\n",
        "\n",
        "with open(glove_path, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embedding_matrix[word] = vector\n",
        "\n",
        "embedding_matrix_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_matrix_dim))\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    vector = glove_embedding_matrix.get(word)\n",
        "\n",
        "    if vector is not None:\n",
        "        embedding_matrix[index] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained_model = pd.DataFrame(\n",
        "    columns=[\n",
        "            'RNN model', 'hiddedn activation function', 'output activation function', 'optimizer', \n",
        "            'accuracy', 'model history', 'model', 'saved_model_path'\n",
        "            ])\n",
        "\n",
        "rnn_models = ['GRU', \"LSTM\"]\n",
        "hidded_activation_functions = ['tanh', 'sigmoid', 'softmax']\n",
        "output_activation_functions = ['sigmoid', 'softmax']\n",
        "optimizers = ['adam', 'rmsprop']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "UKeKG6ZZfe7B",
        "outputId": "4cf6ae51-aa5c-47b5-dafb-811e0b8b15f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 278s 146ms/step - loss: 1.0086 - accuracy: 0.5985 - val_loss: 0.7469 - val_accuracy: 0.7288\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 286s 170ms/step - loss: 0.5364 - accuracy: 0.8179 - val_loss: 0.4884 - val_accuracy: 0.8335\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 314s 186ms/step - loss: 0.3323 - accuracy: 0.8900 - val_loss: 0.4498 - val_accuracy: 0.8472\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 269s 160ms/step - loss: 0.2473 - accuracy: 0.9176 - val_loss: 0.3957 - val_accuracy: 0.8672\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 236s 140ms/step - loss: 0.1956 - accuracy: 0.9331 - val_loss: 0.3948 - val_accuracy: 0.8757\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 240s 142ms/step - loss: 0.1636 - accuracy: 0.9427 - val_loss: 0.3986 - val_accuracy: 0.8838\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 238s 141ms/step - loss: 0.1419 - accuracy: 0.9487 - val_loss: 0.4219 - val_accuracy: 0.8823\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 242s 143ms/step - loss: 0.1243 - accuracy: 0.9533 - val_loss: 0.4176 - val_accuracy: 0.8843\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 295s 175ms/step - loss: 0.1118 - accuracy: 0.9571 - val_loss: 0.4393 - val_accuracy: 0.8855\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 302s 179ms/step - loss: 0.1024 - accuracy: 0.9601 - val_loss: 0.4571 - val_accuracy: 0.8912\n",
            "469/469 [==============================] - 14s 30ms/step - loss: 0.4100 - accuracy: 0.8967\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_6 (GRU)                 (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_7 (GRU)                 (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_8 (GRU)                 (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_9 (GRU)                 (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 212s 107ms/step - loss: 1.1206 - accuracy: 0.5343 - val_loss: 1.0338 - val_accuracy: 0.5797\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 182s 108ms/step - loss: 0.9111 - accuracy: 0.6469 - val_loss: 0.8712 - val_accuracy: 0.6662\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 185s 110ms/step - loss: 0.7298 - accuracy: 0.7325 - val_loss: 0.7484 - val_accuracy: 0.7263\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 178s 106ms/step - loss: 0.5577 - accuracy: 0.8058 - val_loss: 0.6093 - val_accuracy: 0.7890\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 155s 92ms/step - loss: 0.4278 - accuracy: 0.8551 - val_loss: 0.5446 - val_accuracy: 0.8125\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 172s 102ms/step - loss: 0.3377 - accuracy: 0.8877 - val_loss: 0.4864 - val_accuracy: 0.8393\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 139s 82ms/step - loss: 0.2762 - accuracy: 0.9090 - val_loss: 0.4677 - val_accuracy: 0.8470\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 140s 83ms/step - loss: 0.2310 - accuracy: 0.9224 - val_loss: 0.5122 - val_accuracy: 0.8447\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 140s 83ms/step - loss: 0.1990 - accuracy: 0.9329 - val_loss: 0.4446 - val_accuracy: 0.8570\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 155s 92ms/step - loss: 0.1755 - accuracy: 0.9398 - val_loss: 0.4582 - val_accuracy: 0.8605\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 211s 125ms/step - loss: 0.1595 - accuracy: 0.9447 - val_loss: 0.5067 - val_accuracy: 0.8540\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 185s 110ms/step - loss: 0.1426 - accuracy: 0.9499 - val_loss: 0.4742 - val_accuracy: 0.8677\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 178s 106ms/step - loss: 0.1322 - accuracy: 0.9520 - val_loss: 0.4773 - val_accuracy: 0.8670\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 177s 105ms/step - loss: 0.1211 - accuracy: 0.9556 - val_loss: 0.5106 - val_accuracy: 0.8707\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.5097 - accuracy: 0.8723\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_10 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_12 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_13 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_14 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 302s 161ms/step - loss: 0.9920 - accuracy: 0.6061 - val_loss: 0.7268 - val_accuracy: 0.7385\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 258s 153ms/step - loss: 0.5229 - accuracy: 0.8238 - val_loss: 0.5014 - val_accuracy: 0.8283\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 259s 153ms/step - loss: 0.3293 - accuracy: 0.8914 - val_loss: 0.4368 - val_accuracy: 0.8527\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 258s 153ms/step - loss: 0.2449 - accuracy: 0.9184 - val_loss: 0.4062 - val_accuracy: 0.8703\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 258s 153ms/step - loss: 0.1969 - accuracy: 0.9327 - val_loss: 0.3900 - val_accuracy: 0.8757\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 257s 152ms/step - loss: 0.1656 - accuracy: 0.9416 - val_loss: 0.4055 - val_accuracy: 0.8775\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 257s 152ms/step - loss: 0.1425 - accuracy: 0.9484 - val_loss: 0.4162 - val_accuracy: 0.8790\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 257s 152ms/step - loss: 0.1253 - accuracy: 0.9531 - val_loss: 0.4220 - val_accuracy: 0.8865\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 257s 152ms/step - loss: 0.1140 - accuracy: 0.9573 - val_loss: 0.4230 - val_accuracy: 0.8872\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 257s 152ms/step - loss: 0.1054 - accuracy: 0.9605 - val_loss: 0.4495 - val_accuracy: 0.8852\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 0.4040 - accuracy: 0.8911\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_15 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_16 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_17 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_18 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_19 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 226s 117ms/step - loss: 1.1239 - accuracy: 0.5358 - val_loss: 1.0022 - val_accuracy: 0.5892\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 178s 105ms/step - loss: 0.9158 - accuracy: 0.6442 - val_loss: 0.8666 - val_accuracy: 0.6657\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 178s 106ms/step - loss: 0.7325 - accuracy: 0.7313 - val_loss: 0.7349 - val_accuracy: 0.7283\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 178s 106ms/step - loss: 0.5613 - accuracy: 0.8027 - val_loss: 0.6242 - val_accuracy: 0.7840\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 192s 114ms/step - loss: 0.4322 - accuracy: 0.8537 - val_loss: 0.5455 - val_accuracy: 0.8112\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 222s 132ms/step - loss: 0.3440 - accuracy: 0.8835 - val_loss: 0.5286 - val_accuracy: 0.8255\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 205s 122ms/step - loss: 0.2835 - accuracy: 0.9037 - val_loss: 0.5037 - val_accuracy: 0.8357\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 179s 106ms/step - loss: 0.2381 - accuracy: 0.9192 - val_loss: 0.4468 - val_accuracy: 0.8553\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 153s 91ms/step - loss: 0.2049 - accuracy: 0.9298 - val_loss: 0.4459 - val_accuracy: 0.8630\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 154s 91ms/step - loss: 0.1788 - accuracy: 0.9378 - val_loss: 0.4490 - val_accuracy: 0.8623\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 154s 91ms/step - loss: 0.1611 - accuracy: 0.9435 - val_loss: 0.4652 - val_accuracy: 0.8665\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 155s 92ms/step - loss: 0.1459 - accuracy: 0.9483 - val_loss: 0.4520 - val_accuracy: 0.8742\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 154s 91ms/step - loss: 0.1351 - accuracy: 0.9506 - val_loss: 0.4491 - val_accuracy: 0.8788\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 155s 92ms/step - loss: 0.1248 - accuracy: 0.9546 - val_loss: 0.4860 - val_accuracy: 0.8740\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.4817 - accuracy: 0.8743\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_20 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_21 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_22 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_23 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_24 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 246s 137ms/step - loss: 1.2254 - accuracy: 0.4310 - val_loss: 1.0843 - val_accuracy: 0.5130\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 228s 135ms/step - loss: 0.9665 - accuracy: 0.5747 - val_loss: 0.9073 - val_accuracy: 0.6248\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 230s 136ms/step - loss: 0.7793 - accuracy: 0.6765 - val_loss: 0.8097 - val_accuracy: 0.6722\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 229s 135ms/step - loss: 0.6651 - accuracy: 0.7193 - val_loss: 0.7437 - val_accuracy: 0.6970\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 239s 142ms/step - loss: 0.5922 - accuracy: 0.7423 - val_loss: 0.7144 - val_accuracy: 0.7135\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 231s 137ms/step - loss: 0.5411 - accuracy: 0.7589 - val_loss: 0.6996 - val_accuracy: 0.7198\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 229s 136ms/step - loss: 0.5065 - accuracy: 0.7676 - val_loss: 0.6885 - val_accuracy: 0.7233\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 229s 136ms/step - loss: 0.4835 - accuracy: 0.7725 - val_loss: 0.6699 - val_accuracy: 0.7202\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 229s 135ms/step - loss: 0.3927 - accuracy: 0.8659 - val_loss: 0.5447 - val_accuracy: 0.8268\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 227s 135ms/step - loss: 0.3028 - accuracy: 0.9035 - val_loss: 0.5144 - val_accuracy: 0.8393\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 228s 135ms/step - loss: 0.2512 - accuracy: 0.9209 - val_loss: 0.5160 - val_accuracy: 0.8453\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 229s 135ms/step - loss: 0.2199 - accuracy: 0.9309 - val_loss: 0.5183 - val_accuracy: 0.8495\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 241s 143ms/step - loss: 0.1959 - accuracy: 0.9373 - val_loss: 0.5165 - val_accuracy: 0.8518\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 259s 154ms/step - loss: 0.1798 - accuracy: 0.9422 - val_loss: 0.5230 - val_accuracy: 0.8565\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 259s 154ms/step - loss: 0.1661 - accuracy: 0.9456 - val_loss: 0.5042 - val_accuracy: 0.8637\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 286s 170ms/step - loss: 0.1560 - accuracy: 0.9507 - val_loss: 0.5220 - val_accuracy: 0.8638\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 266s 158ms/step - loss: 0.1457 - accuracy: 0.9539 - val_loss: 0.5397 - val_accuracy: 0.8575\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 262s 155ms/step - loss: 0.1400 - accuracy: 0.9547 - val_loss: 0.5335 - val_accuracy: 0.8657\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 263s 156ms/step - loss: 0.1320 - accuracy: 0.9572 - val_loss: 0.5331 - val_accuracy: 0.8677\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 251s 149ms/step - loss: 0.1289 - accuracy: 0.9579 - val_loss: 0.5055 - val_accuracy: 0.8692\n",
            "469/469 [==============================] - 13s 28ms/step - loss: 0.4996 - accuracy: 0.8703\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_25 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_26 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_27 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_28 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_29 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 190s 103ms/step - loss: 1.3595 - accuracy: 0.3138 - val_loss: 1.3530 - val_accuracy: 0.3203\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 190s 113ms/step - loss: 1.3560 - accuracy: 0.3141 - val_loss: 1.3518 - val_accuracy: 0.3178\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 194s 115ms/step - loss: 1.3558 - accuracy: 0.3107 - val_loss: 1.3518 - val_accuracy: 0.3182\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 195s 116ms/step - loss: 1.3556 - accuracy: 0.3121 - val_loss: 1.3520 - val_accuracy: 0.3203\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 195s 115ms/step - loss: 1.3549 - accuracy: 0.3146 - val_loss: 1.3519 - val_accuracy: 0.3288\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 184s 109ms/step - loss: 1.3330 - accuracy: 0.3474 - val_loss: 1.2805 - val_accuracy: 0.4142\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 192s 114ms/step - loss: 1.2708 - accuracy: 0.4184 - val_loss: 1.2330 - val_accuracy: 0.4467\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 178s 105ms/step - loss: 1.2179 - accuracy: 0.4709 - val_loss: 1.1978 - val_accuracy: 0.4840\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 159s 94ms/step - loss: 1.1431 - accuracy: 0.5249 - val_loss: 1.1001 - val_accuracy: 0.5505\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 160s 95ms/step - loss: 1.0283 - accuracy: 0.5920 - val_loss: 0.9892 - val_accuracy: 0.6137\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 162s 96ms/step - loss: 0.9040 - accuracy: 0.6559 - val_loss: 0.9364 - val_accuracy: 0.6352\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 163s 97ms/step - loss: 0.7958 - accuracy: 0.7139 - val_loss: 0.8123 - val_accuracy: 0.7000\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 167s 99ms/step - loss: 0.7090 - accuracy: 0.7540 - val_loss: 0.7545 - val_accuracy: 0.7302\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 174s 103ms/step - loss: 0.6395 - accuracy: 0.7820 - val_loss: 0.7382 - val_accuracy: 0.7400\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 182s 108ms/step - loss: 0.5803 - accuracy: 0.8065 - val_loss: 0.6763 - val_accuracy: 0.7578\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 178s 105ms/step - loss: 0.5310 - accuracy: 0.8234 - val_loss: 0.6583 - val_accuracy: 0.7693\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 183s 109ms/step - loss: 0.4880 - accuracy: 0.8396 - val_loss: 0.6278 - val_accuracy: 0.7853\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 178s 105ms/step - loss: 0.4529 - accuracy: 0.8512 - val_loss: 0.6086 - val_accuracy: 0.7930\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 177s 105ms/step - loss: 0.4208 - accuracy: 0.8622 - val_loss: 0.6037 - val_accuracy: 0.7980\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 162s 96ms/step - loss: 0.3908 - accuracy: 0.8723 - val_loss: 0.5811 - val_accuracy: 0.8080\n",
            "Epoch 21/100\n",
            "1688/1688 [==============================] - 156s 92ms/step - loss: 0.3680 - accuracy: 0.8792 - val_loss: 0.5853 - val_accuracy: 0.8135\n",
            "Epoch 22/100\n",
            "1688/1688 [==============================] - 156s 92ms/step - loss: 0.3472 - accuracy: 0.8859 - val_loss: 0.5829 - val_accuracy: 0.8135\n",
            "Epoch 23/100\n",
            "1688/1688 [==============================] - 155s 92ms/step - loss: 0.3301 - accuracy: 0.8929 - val_loss: 0.5773 - val_accuracy: 0.8145\n",
            "Epoch 24/100\n",
            "1688/1688 [==============================] - 156s 93ms/step - loss: 0.3106 - accuracy: 0.8983 - val_loss: 0.5719 - val_accuracy: 0.8220\n",
            "Epoch 25/100\n",
            "1688/1688 [==============================] - 155s 92ms/step - loss: 0.2980 - accuracy: 0.9030 - val_loss: 0.5751 - val_accuracy: 0.8127\n",
            "Epoch 26/100\n",
            "1688/1688 [==============================] - 155s 92ms/step - loss: 0.2830 - accuracy: 0.9084 - val_loss: 0.5382 - val_accuracy: 0.8273\n",
            "Epoch 27/100\n",
            "1688/1688 [==============================] - 158s 93ms/step - loss: 0.2684 - accuracy: 0.9135 - val_loss: 0.5506 - val_accuracy: 0.8280\n",
            "Epoch 28/100\n",
            "1688/1688 [==============================] - 156s 93ms/step - loss: 0.2599 - accuracy: 0.9162 - val_loss: 0.5553 - val_accuracy: 0.8247\n",
            "Epoch 29/100\n",
            "1688/1688 [==============================] - 158s 93ms/step - loss: 0.2495 - accuracy: 0.9198 - val_loss: 0.5672 - val_accuracy: 0.8277\n",
            "Epoch 30/100\n",
            "1688/1688 [==============================] - 158s 93ms/step - loss: 0.2395 - accuracy: 0.9241 - val_loss: 0.5515 - val_accuracy: 0.8320\n",
            "Epoch 31/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.2315 - accuracy: 0.9257 - val_loss: 0.5435 - val_accuracy: 0.8297\n",
            "469/469 [==============================] - 11s 22ms/step - loss: 0.5578 - accuracy: 0.8278\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_30 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_31 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_32 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_33 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_34 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 250s 140ms/step - loss: 1.2121 - accuracy: 0.4451 - val_loss: 1.0504 - val_accuracy: 0.5433\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 233s 138ms/step - loss: 0.9134 - accuracy: 0.6307 - val_loss: 0.8366 - val_accuracy: 0.6832\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 234s 139ms/step - loss: 0.6988 - accuracy: 0.7618 - val_loss: 0.7079 - val_accuracy: 0.7605\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 233s 138ms/step - loss: 0.5487 - accuracy: 0.8305 - val_loss: 0.6322 - val_accuracy: 0.7978\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 232s 138ms/step - loss: 0.4404 - accuracy: 0.8691 - val_loss: 0.5796 - val_accuracy: 0.8142\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 233s 138ms/step - loss: 0.3661 - accuracy: 0.8909 - val_loss: 0.5233 - val_accuracy: 0.8318\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 233s 138ms/step - loss: 0.3099 - accuracy: 0.9072 - val_loss: 0.5059 - val_accuracy: 0.8395\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 234s 139ms/step - loss: 0.2717 - accuracy: 0.9161 - val_loss: 0.4930 - val_accuracy: 0.8452\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 237s 140ms/step - loss: 0.2417 - accuracy: 0.9252 - val_loss: 0.4817 - val_accuracy: 0.8537\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 234s 139ms/step - loss: 0.2185 - accuracy: 0.9312 - val_loss: 0.4774 - val_accuracy: 0.8558\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 234s 138ms/step - loss: 0.1962 - accuracy: 0.9373 - val_loss: 0.4666 - val_accuracy: 0.8598\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 233s 138ms/step - loss: 0.1814 - accuracy: 0.9413 - val_loss: 0.4823 - val_accuracy: 0.8622\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 239s 142ms/step - loss: 0.1666 - accuracy: 0.9451 - val_loss: 0.4750 - val_accuracy: 0.8608\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 234s 139ms/step - loss: 0.1569 - accuracy: 0.9486 - val_loss: 0.4791 - val_accuracy: 0.8667\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 255s 151ms/step - loss: 0.1458 - accuracy: 0.9510 - val_loss: 0.4753 - val_accuracy: 0.8682\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 250s 148ms/step - loss: 0.1378 - accuracy: 0.9533 - val_loss: 0.4816 - val_accuracy: 0.8698\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.4598 - accuracy: 0.8740\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_35 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_36 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_37 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_38 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_39 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 176s 91ms/step - loss: 1.3636 - accuracy: 0.3017 - val_loss: 1.3553 - val_accuracy: 0.3025\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 162s 96ms/step - loss: 1.3569 - accuracy: 0.3117 - val_loss: 1.3531 - val_accuracy: 0.3265\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 172s 102ms/step - loss: 1.3559 - accuracy: 0.3144 - val_loss: 1.3528 - val_accuracy: 0.3272\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 153s 91ms/step - loss: 1.3413 - accuracy: 0.3442 - val_loss: 1.2943 - val_accuracy: 0.4108\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 162s 96ms/step - loss: 1.2696 - accuracy: 0.4305 - val_loss: 1.2229 - val_accuracy: 0.4687\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 165s 98ms/step - loss: 1.2084 - accuracy: 0.4807 - val_loss: 1.1648 - val_accuracy: 0.5092\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 168s 100ms/step - loss: 1.1361 - accuracy: 0.5272 - val_loss: 1.1220 - val_accuracy: 0.5457\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 162s 96ms/step - loss: 1.0418 - accuracy: 0.5825 - val_loss: 1.0227 - val_accuracy: 0.5923\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 160s 95ms/step - loss: 0.9379 - accuracy: 0.6362 - val_loss: 0.9610 - val_accuracy: 0.6178\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 162s 96ms/step - loss: 0.8482 - accuracy: 0.6802 - val_loss: 0.8906 - val_accuracy: 0.6585\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 167s 99ms/step - loss: 0.7703 - accuracy: 0.7146 - val_loss: 0.8265 - val_accuracy: 0.6917\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 161s 96ms/step - loss: 0.7069 - accuracy: 0.7414 - val_loss: 0.7941 - val_accuracy: 0.7060\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 163s 97ms/step - loss: 0.6508 - accuracy: 0.7643 - val_loss: 0.7647 - val_accuracy: 0.7148\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 179s 106ms/step - loss: 0.6031 - accuracy: 0.7822 - val_loss: 0.7372 - val_accuracy: 0.7350\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 188s 111ms/step - loss: 0.5582 - accuracy: 0.8004 - val_loss: 0.6943 - val_accuracy: 0.7498\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 181s 108ms/step - loss: 0.5161 - accuracy: 0.8155 - val_loss: 0.6759 - val_accuracy: 0.7585\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 175s 104ms/step - loss: 0.4765 - accuracy: 0.8299 - val_loss: 0.6577 - val_accuracy: 0.7717\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 183s 108ms/step - loss: 0.4418 - accuracy: 0.8416 - val_loss: 0.6290 - val_accuracy: 0.7828\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 166s 98ms/step - loss: 0.4100 - accuracy: 0.8545 - val_loss: 0.6251 - val_accuracy: 0.7877\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 160s 95ms/step - loss: 0.3793 - accuracy: 0.8672 - val_loss: 0.6166 - val_accuracy: 0.7900\n",
            "Epoch 21/100\n",
            "1688/1688 [==============================] - 165s 98ms/step - loss: 0.3548 - accuracy: 0.8757 - val_loss: 0.5979 - val_accuracy: 0.8022\n",
            "Epoch 22/100\n",
            "1688/1688 [==============================] - 161s 96ms/step - loss: 0.3287 - accuracy: 0.8837 - val_loss: 0.6131 - val_accuracy: 0.8010\n",
            "Epoch 23/100\n",
            "1688/1688 [==============================] - 161s 96ms/step - loss: 0.3092 - accuracy: 0.8893 - val_loss: 0.5960 - val_accuracy: 0.8053\n",
            "Epoch 24/100\n",
            "1688/1688 [==============================] - 165s 98ms/step - loss: 0.2913 - accuracy: 0.8966 - val_loss: 0.5893 - val_accuracy: 0.8117\n",
            "Epoch 25/100\n",
            "1688/1688 [==============================] - 163s 97ms/step - loss: 0.2744 - accuracy: 0.9009 - val_loss: 0.6683 - val_accuracy: 0.7908\n",
            "Epoch 26/100\n",
            "1688/1688 [==============================] - 147s 87ms/step - loss: 0.2623 - accuracy: 0.9055 - val_loss: 0.6148 - val_accuracy: 0.8107\n",
            "Epoch 27/100\n",
            "1688/1688 [==============================] - 167s 99ms/step - loss: 0.2475 - accuracy: 0.9100 - val_loss: 0.5985 - val_accuracy: 0.8185\n",
            "Epoch 28/100\n",
            "1688/1688 [==============================] - 166s 98ms/step - loss: 0.2392 - accuracy: 0.9137 - val_loss: 0.6027 - val_accuracy: 0.8222\n",
            "Epoch 29/100\n",
            "1688/1688 [==============================] - 170s 101ms/step - loss: 0.2293 - accuracy: 0.9183 - val_loss: 0.6048 - val_accuracy: 0.8212\n",
            "469/469 [==============================] - 12s 26ms/step - loss: 0.5899 - accuracy: 0.8193\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_40 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_41 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_42 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_43 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_44 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 280s 157ms/step - loss: 1.3649 - accuracy: 0.3043 - val_loss: 1.3591 - val_accuracy: 0.3078\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 282s 167ms/step - loss: 1.3575 - accuracy: 0.3135 - val_loss: 1.3529 - val_accuracy: 0.3247\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 261s 154ms/step - loss: 1.3553 - accuracy: 0.3140 - val_loss: 1.3422 - val_accuracy: 0.3433\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 253s 150ms/step - loss: 1.2365 - accuracy: 0.4370 - val_loss: 1.1550 - val_accuracy: 0.4822\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 258s 153ms/step - loss: 1.0638 - accuracy: 0.5103 - val_loss: 1.0173 - val_accuracy: 0.5285\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 247s 147ms/step - loss: 0.9372 - accuracy: 0.5712 - val_loss: 0.9473 - val_accuracy: 0.5850\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 249s 147ms/step - loss: 0.8504 - accuracy: 0.6360 - val_loss: 0.8914 - val_accuracy: 0.6293\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 251s 149ms/step - loss: 0.7777 - accuracy: 0.6799 - val_loss: 0.8232 - val_accuracy: 0.6767\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 247s 146ms/step - loss: 0.7085 - accuracy: 0.7203 - val_loss: 0.7665 - val_accuracy: 0.7143\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 254s 151ms/step - loss: 0.6278 - accuracy: 0.7679 - val_loss: 0.7108 - val_accuracy: 0.7463\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 245s 145ms/step - loss: 0.5504 - accuracy: 0.8062 - val_loss: 0.6764 - val_accuracy: 0.7637\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 246s 146ms/step - loss: 0.4923 - accuracy: 0.8299 - val_loss: 0.6467 - val_accuracy: 0.7800\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 246s 146ms/step - loss: 0.4452 - accuracy: 0.8481 - val_loss: 0.6362 - val_accuracy: 0.7832\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 246s 146ms/step - loss: 0.4117 - accuracy: 0.8594 - val_loss: 0.6256 - val_accuracy: 0.7933\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 235s 139ms/step - loss: 0.3852 - accuracy: 0.8705 - val_loss: 0.6075 - val_accuracy: 0.8005\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 236s 140ms/step - loss: 0.3626 - accuracy: 0.8786 - val_loss: 0.5982 - val_accuracy: 0.8083\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 235s 139ms/step - loss: 0.3456 - accuracy: 0.8840 - val_loss: 0.5883 - val_accuracy: 0.8132\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 235s 139ms/step - loss: 0.3275 - accuracy: 0.8908 - val_loss: 0.5749 - val_accuracy: 0.8175\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 235s 139ms/step - loss: 0.3140 - accuracy: 0.8941 - val_loss: 0.5609 - val_accuracy: 0.8253\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 235s 139ms/step - loss: 0.2996 - accuracy: 0.9001 - val_loss: 0.5540 - val_accuracy: 0.8252\n",
            "Epoch 21/100\n",
            "1688/1688 [==============================] - 235s 139ms/step - loss: 0.2865 - accuracy: 0.9045 - val_loss: 0.5465 - val_accuracy: 0.8332\n",
            "Epoch 22/100\n",
            "1688/1688 [==============================] - 235s 139ms/step - loss: 0.2726 - accuracy: 0.9093 - val_loss: 0.5352 - val_accuracy: 0.8348\n",
            "Epoch 23/100\n",
            "1688/1688 [==============================] - 262s 155ms/step - loss: 0.2616 - accuracy: 0.9127 - val_loss: 0.5282 - val_accuracy: 0.8352\n",
            "Epoch 24/100\n",
            "1688/1688 [==============================] - 268s 159ms/step - loss: 0.2493 - accuracy: 0.9153 - val_loss: 0.5203 - val_accuracy: 0.8407\n",
            "Epoch 25/100\n",
            "1688/1688 [==============================] - 256s 152ms/step - loss: 0.2456 - accuracy: 0.9161 - val_loss: 0.5308 - val_accuracy: 0.8413\n",
            "Epoch 26/100\n",
            "1688/1688 [==============================] - 260s 154ms/step - loss: 0.2346 - accuracy: 0.9201 - val_loss: 0.5101 - val_accuracy: 0.8447\n",
            "Epoch 27/100\n",
            "1688/1688 [==============================] - 273s 162ms/step - loss: 0.2279 - accuracy: 0.9213 - val_loss: 0.5172 - val_accuracy: 0.8488\n",
            "Epoch 28/100\n",
            "1688/1688 [==============================] - 271s 160ms/step - loss: 0.2168 - accuracy: 0.9250 - val_loss: 0.5159 - val_accuracy: 0.8502\n",
            "Epoch 29/100\n",
            "1688/1688 [==============================] - 225s 133ms/step - loss: 0.2115 - accuracy: 0.9269 - val_loss: 0.5122 - val_accuracy: 0.8510\n",
            "Epoch 30/100\n",
            "1688/1688 [==============================] - 240s 142ms/step - loss: 0.2055 - accuracy: 0.9284 - val_loss: 0.5185 - val_accuracy: 0.8527\n",
            "Epoch 31/100\n",
            "1688/1688 [==============================] - 248s 147ms/step - loss: 0.1989 - accuracy: 0.9300 - val_loss: 0.5165 - val_accuracy: 0.8548\n",
            "469/469 [==============================] - 13s 27ms/step - loss: 0.4961 - accuracy: 0.8528\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_45 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_46 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_47 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_48 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_49 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 187s 103ms/step - loss: 1.3638 - accuracy: 0.3136 - val_loss: 1.3569 - val_accuracy: 0.3212\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 170s 101ms/step - loss: 1.3572 - accuracy: 0.3155 - val_loss: 1.3531 - val_accuracy: 0.3212\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 132s 78ms/step - loss: 1.3560 - accuracy: 0.3141 - val_loss: 1.3521 - val_accuracy: 0.3212\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 113s 67ms/step - loss: 1.3556 - accuracy: 0.3144 - val_loss: 1.3537 - val_accuracy: 0.3257\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 111s 66ms/step - loss: 1.3554 - accuracy: 0.3132 - val_loss: 1.3518 - val_accuracy: 0.3153\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 104s 62ms/step - loss: 1.3554 - accuracy: 0.3140 - val_loss: 1.3517 - val_accuracy: 0.3220\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 116s 69ms/step - loss: 1.3552 - accuracy: 0.3150 - val_loss: 1.3530 - val_accuracy: 0.3197\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 116s 69ms/step - loss: 1.3554 - accuracy: 0.3144 - val_loss: 1.3517 - val_accuracy: 0.3193\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 104s 62ms/step - loss: 1.3550 - accuracy: 0.3137 - val_loss: 1.3515 - val_accuracy: 0.3158\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 102s 61ms/step - loss: 1.3551 - accuracy: 0.3140 - val_loss: 1.3524 - val_accuracy: 0.3197\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 105s 62ms/step - loss: 1.3552 - accuracy: 0.3127 - val_loss: 1.3517 - val_accuracy: 0.3212\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 117s 69ms/step - loss: 1.3552 - accuracy: 0.3142 - val_loss: 1.3514 - val_accuracy: 0.3198\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 148s 88ms/step - loss: 1.3550 - accuracy: 0.3148 - val_loss: 1.3517 - val_accuracy: 0.3165\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 148s 88ms/step - loss: 1.3551 - accuracy: 0.3125 - val_loss: 1.3515 - val_accuracy: 0.3268\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 178s 105ms/step - loss: 1.3550 - accuracy: 0.3133 - val_loss: 1.3513 - val_accuracy: 0.3265\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 169s 100ms/step - loss: 1.3548 - accuracy: 0.3163 - val_loss: 1.3519 - val_accuracy: 0.3212\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 170s 101ms/step - loss: 1.3549 - accuracy: 0.3127 - val_loss: 1.3511 - val_accuracy: 0.3220\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 158s 94ms/step - loss: 1.3549 - accuracy: 0.3137 - val_loss: 1.3511 - val_accuracy: 0.3153\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 165s 98ms/step - loss: 1.3548 - accuracy: 0.3127 - val_loss: 1.3514 - val_accuracy: 0.3280\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 178s 105ms/step - loss: 1.3548 - accuracy: 0.3126 - val_loss: 1.3520 - val_accuracy: 0.3237\n",
            "Epoch 21/100\n",
            "1688/1688 [==============================] - 174s 103ms/step - loss: 1.3548 - accuracy: 0.3138 - val_loss: 1.3508 - val_accuracy: 0.3193\n",
            "Epoch 22/100\n",
            "1688/1688 [==============================] - 158s 93ms/step - loss: 1.3547 - accuracy: 0.3140 - val_loss: 1.3522 - val_accuracy: 0.3212\n",
            "Epoch 23/100\n",
            "1688/1688 [==============================] - 159s 94ms/step - loss: 1.3545 - accuracy: 0.3143 - val_loss: 1.3507 - val_accuracy: 0.3253\n",
            "Epoch 24/100\n",
            "1688/1688 [==============================] - 168s 99ms/step - loss: 1.3546 - accuracy: 0.3133 - val_loss: 1.3513 - val_accuracy: 0.3212\n",
            "Epoch 25/100\n",
            "1688/1688 [==============================] - 177s 105ms/step - loss: 1.3547 - accuracy: 0.3145 - val_loss: 1.3514 - val_accuracy: 0.3203\n",
            "Epoch 26/100\n",
            "1688/1688 [==============================] - 170s 101ms/step - loss: 1.3546 - accuracy: 0.3130 - val_loss: 1.3513 - val_accuracy: 0.3265\n",
            "Epoch 27/100\n",
            "1688/1688 [==============================] - 169s 100ms/step - loss: 1.3546 - accuracy: 0.3121 - val_loss: 1.3510 - val_accuracy: 0.3173\n",
            "Epoch 28/100\n",
            "1688/1688 [==============================] - 166s 98ms/step - loss: 1.3544 - accuracy: 0.3136 - val_loss: 1.3518 - val_accuracy: 0.3212\n",
            "469/469 [==============================] - 11s 23ms/step - loss: 1.3567 - accuracy: 0.3112\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_50 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_51 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_52 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_53 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_54 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 264s 148ms/step - loss: 1.3667 - accuracy: 0.3048 - val_loss: 1.3597 - val_accuracy: 0.3197\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 254s 151ms/step - loss: 1.3572 - accuracy: 0.3155 - val_loss: 1.3522 - val_accuracy: 0.3197\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 288s 171ms/step - loss: 1.3556 - accuracy: 0.3140 - val_loss: 1.3515 - val_accuracy: 0.3212\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 291s 172ms/step - loss: 1.2879 - accuracy: 0.3854 - val_loss: 1.1993 - val_accuracy: 0.4592\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 269s 159ms/step - loss: 1.1118 - accuracy: 0.5035 - val_loss: 1.0552 - val_accuracy: 0.5495\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 236s 140ms/step - loss: 0.9697 - accuracy: 0.5895 - val_loss: 0.9606 - val_accuracy: 0.5958\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 246s 146ms/step - loss: 0.8874 - accuracy: 0.6351 - val_loss: 0.9208 - val_accuracy: 0.6185\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 249s 148ms/step - loss: 0.8270 - accuracy: 0.6659 - val_loss: 0.8855 - val_accuracy: 0.6477\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 240s 142ms/step - loss: 0.7776 - accuracy: 0.6919 - val_loss: 0.8573 - val_accuracy: 0.6670\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 247s 146ms/step - loss: 0.7325 - accuracy: 0.7177 - val_loss: 0.8204 - val_accuracy: 0.6923\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 39314s 23s/step - loss: 0.6890 - accuracy: 0.7407 - val_loss: 0.7904 - val_accuracy: 0.7067\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 172s 102ms/step - loss: 0.6465 - accuracy: 0.7597 - val_loss: 0.7629 - val_accuracy: 0.7267\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 164s 97ms/step - loss: 0.6049 - accuracy: 0.7822 - val_loss: 0.7352 - val_accuracy: 0.7380\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 164s 97ms/step - loss: 0.5626 - accuracy: 0.8012 - val_loss: 0.7083 - val_accuracy: 0.7520\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 164s 97ms/step - loss: 0.5181 - accuracy: 0.8211 - val_loss: 0.6866 - val_accuracy: 0.7622\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 174s 103ms/step - loss: 0.4863 - accuracy: 0.8338 - val_loss: 0.6839 - val_accuracy: 0.7658\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 208s 123ms/step - loss: 0.4489 - accuracy: 0.8482 - val_loss: 0.6599 - val_accuracy: 0.7750\n",
            "Epoch 18/100\n",
            "1688/1688 [==============================] - 258s 153ms/step - loss: 0.4215 - accuracy: 0.8587 - val_loss: 0.6471 - val_accuracy: 0.7878\n",
            "Epoch 19/100\n",
            "1688/1688 [==============================] - 263s 156ms/step - loss: 0.3963 - accuracy: 0.8674 - val_loss: 0.6505 - val_accuracy: 0.7857\n",
            "Epoch 20/100\n",
            "1688/1688 [==============================] - 281s 166ms/step - loss: 0.3761 - accuracy: 0.8747 - val_loss: 0.6235 - val_accuracy: 0.7960\n",
            "Epoch 21/100\n",
            "1688/1688 [==============================] - 266s 158ms/step - loss: 0.3535 - accuracy: 0.8812 - val_loss: 0.6239 - val_accuracy: 0.8007\n",
            "Epoch 22/100\n",
            "1688/1688 [==============================] - 238s 141ms/step - loss: 0.3345 - accuracy: 0.8896 - val_loss: 0.6216 - val_accuracy: 0.8047\n",
            "Epoch 23/100\n",
            "1688/1688 [==============================] - 225s 133ms/step - loss: 0.3224 - accuracy: 0.8933 - val_loss: 0.6264 - val_accuracy: 0.8047\n",
            "Epoch 24/100\n",
            "1688/1688 [==============================] - 223s 132ms/step - loss: 0.3074 - accuracy: 0.8984 - val_loss: 0.6431 - val_accuracy: 0.8068\n",
            "Epoch 25/100\n",
            "1688/1688 [==============================] - 226s 134ms/step - loss: 0.2984 - accuracy: 0.9026 - val_loss: 0.6234 - val_accuracy: 0.8128\n",
            "Epoch 26/100\n",
            "1688/1688 [==============================] - 220s 130ms/step - loss: 0.2871 - accuracy: 0.9053 - val_loss: 0.6157 - val_accuracy: 0.8197\n",
            "Epoch 27/100\n",
            "1688/1688 [==============================] - 219s 130ms/step - loss: 0.2728 - accuracy: 0.9096 - val_loss: 0.6287 - val_accuracy: 0.8207\n",
            "Epoch 28/100\n",
            "1688/1688 [==============================] - 220s 130ms/step - loss: 0.2671 - accuracy: 0.9112 - val_loss: 0.6299 - val_accuracy: 0.8205\n",
            "Epoch 29/100\n",
            "1688/1688 [==============================] - 220s 130ms/step - loss: 0.2568 - accuracy: 0.9146 - val_loss: 0.6384 - val_accuracy: 0.8207\n",
            "Epoch 30/100\n",
            "1688/1688 [==============================] - 220s 130ms/step - loss: 0.2468 - accuracy: 0.9186 - val_loss: 0.6243 - val_accuracy: 0.8260\n",
            "Epoch 31/100\n",
            "1688/1688 [==============================] - 220s 130ms/step - loss: 0.2392 - accuracy: 0.9192 - val_loss: 0.6279 - val_accuracy: 0.8247\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 0.6356 - accuracy: 0.8265\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_55 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_56 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_57 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_58 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_59 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 162s 88ms/step - loss: 1.3617 - accuracy: 0.3072 - val_loss: 1.3567 - val_accuracy: 0.3203\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 147s 87ms/step - loss: 1.3569 - accuracy: 0.3143 - val_loss: 1.3529 - val_accuracy: 0.3198\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 146s 86ms/step - loss: 1.3559 - accuracy: 0.3131 - val_loss: 1.3520 - val_accuracy: 0.3173\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 144s 85ms/step - loss: 1.3557 - accuracy: 0.3122 - val_loss: 1.3527 - val_accuracy: 0.3212\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 145s 86ms/step - loss: 1.3554 - accuracy: 0.3132 - val_loss: 1.3531 - val_accuracy: 0.3260\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 144s 85ms/step - loss: 1.3554 - accuracy: 0.3152 - val_loss: 1.3521 - val_accuracy: 0.3212\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 145s 86ms/step - loss: 1.3553 - accuracy: 0.3132 - val_loss: 1.3520 - val_accuracy: 0.3212\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 145s 86ms/step - loss: 1.3554 - accuracy: 0.3103 - val_loss: 1.3536 - val_accuracy: 0.3197\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 146s 86ms/step - loss: 1.3552 - accuracy: 0.3132 - val_loss: 1.3520 - val_accuracy: 0.3212\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 144s 86ms/step - loss: 1.3553 - accuracy: 0.3117 - val_loss: 1.3520 - val_accuracy: 0.3265\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 144s 85ms/step - loss: 1.3551 - accuracy: 0.3138 - val_loss: 1.3521 - val_accuracy: 0.3203\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 145s 86ms/step - loss: 1.3551 - accuracy: 0.3145 - val_loss: 1.3514 - val_accuracy: 0.3167\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 145s 86ms/step - loss: 1.3550 - accuracy: 0.3163 - val_loss: 1.3517 - val_accuracy: 0.3212\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 148s 88ms/step - loss: 1.3550 - accuracy: 0.3133 - val_loss: 1.3519 - val_accuracy: 0.3212\n",
            "Epoch 15/100\n",
            "1688/1688 [==============================] - 144s 85ms/step - loss: 1.3548 - accuracy: 0.3116 - val_loss: 1.3527 - val_accuracy: 0.3212\n",
            "Epoch 16/100\n",
            "1688/1688 [==============================] - 145s 86ms/step - loss: 1.3547 - accuracy: 0.3159 - val_loss: 1.3521 - val_accuracy: 0.3203\n",
            "Epoch 17/100\n",
            "1688/1688 [==============================] - 144s 85ms/step - loss: 1.3547 - accuracy: 0.3144 - val_loss: 1.3520 - val_accuracy: 0.3212\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 1.3567 - accuracy: 0.3112\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_60 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_61 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_62 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_63 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_64 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 263s 138ms/step - loss: 1.0107 - accuracy: 0.5980 - val_loss: 0.7388 - val_accuracy: 0.7388\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 226s 134ms/step - loss: 0.5362 - accuracy: 0.8203 - val_loss: 0.5066 - val_accuracy: 0.8303\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 2068s 1s/step - loss: 0.3384 - accuracy: 0.8899 - val_loss: 0.4391 - val_accuracy: 0.8562\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 238s 141ms/step - loss: 0.2506 - accuracy: 0.9178 - val_loss: 0.4236 - val_accuracy: 0.8627\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 249s 147ms/step - loss: 0.2003 - accuracy: 0.9318 - val_loss: 0.4062 - val_accuracy: 0.8742\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 270s 160ms/step - loss: 0.1661 - accuracy: 0.9425 - val_loss: 0.4278 - val_accuracy: 0.8743\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 251s 149ms/step - loss: 0.1458 - accuracy: 0.9478 - val_loss: 0.4165 - val_accuracy: 0.8787\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 223s 132ms/step - loss: 0.1263 - accuracy: 0.9539 - val_loss: 0.4349 - val_accuracy: 0.8828\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 223s 132ms/step - loss: 0.1142 - accuracy: 0.9571 - val_loss: 0.4193 - val_accuracy: 0.8838\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 222s 131ms/step - loss: 0.1058 - accuracy: 0.9597 - val_loss: 0.4908 - val_accuracy: 0.8752\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.4440 - accuracy: 0.8805\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_65 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_66 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_67 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_68 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_55 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_69 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 201s 98ms/step - loss: 1.1173 - accuracy: 0.5374 - val_loss: 1.0372 - val_accuracy: 0.5842\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.9088 - accuracy: 0.6456 - val_loss: 0.8661 - val_accuracy: 0.6688\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 156s 93ms/step - loss: 0.7265 - accuracy: 0.7339 - val_loss: 0.7500 - val_accuracy: 0.7187\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.5562 - accuracy: 0.8056 - val_loss: 0.6160 - val_accuracy: 0.7845\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.4253 - accuracy: 0.8560 - val_loss: 0.5711 - val_accuracy: 0.8028\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 158s 93ms/step - loss: 0.3398 - accuracy: 0.8853 - val_loss: 0.4880 - val_accuracy: 0.8347\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 156s 93ms/step - loss: 0.2791 - accuracy: 0.9067 - val_loss: 0.4752 - val_accuracy: 0.8453\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.2333 - accuracy: 0.9221 - val_loss: 0.4776 - val_accuracy: 0.8505\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 156s 93ms/step - loss: 0.2011 - accuracy: 0.9322 - val_loss: 0.4517 - val_accuracy: 0.8633\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.1761 - accuracy: 0.9405 - val_loss: 0.4763 - val_accuracy: 0.8663\n",
            "Epoch 11/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.1590 - accuracy: 0.9452 - val_loss: 0.4559 - val_accuracy: 0.8715\n",
            "Epoch 12/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.1431 - accuracy: 0.9505 - val_loss: 0.4763 - val_accuracy: 0.8660\n",
            "Epoch 13/100\n",
            "1688/1688 [==============================] - 158s 93ms/step - loss: 0.1346 - accuracy: 0.9528 - val_loss: 0.4736 - val_accuracy: 0.8750\n",
            "Epoch 14/100\n",
            "1688/1688 [==============================] - 157s 93ms/step - loss: 0.1230 - accuracy: 0.9557 - val_loss: 0.5014 - val_accuracy: 0.8765\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.4822 - accuracy: 0.8765\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 27, 100)           2964500   \n",
            "                                                                 \n",
            " gru_70 (GRU)                (None, 27, 128)           88320     \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 27, 128)           0         \n",
            "                                                                 \n",
            " gru_71 (GRU)                (None, 27, 64)            37248     \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 27, 64)            0         \n",
            "                                                                 \n",
            " gru_72 (GRU)                (None, 27, 32)            9408      \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 27, 32)            0         \n",
            "                                                                 \n",
            " gru_73 (GRU)                (None, 27, 16)            2400      \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 27, 16)            0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 27, 64)            1088      \n",
            "                                                                 \n",
            " gru_74 (GRU)                (None, 4)                 840       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,103,824\n",
            "Trainable params: 3,103,824\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1688/1688 [==============================] - 270s 144ms/step - loss: 1.0420 - accuracy: 0.5801 - val_loss: 0.8211 - val_accuracy: 0.6988\n",
            "Epoch 2/100\n",
            "1688/1688 [==============================] - 233s 138ms/step - loss: 0.5665 - accuracy: 0.8123 - val_loss: 0.5325 - val_accuracy: 0.8242\n",
            "Epoch 3/100\n",
            "1688/1688 [==============================] - 233s 138ms/step - loss: 0.3602 - accuracy: 0.8854 - val_loss: 0.4496 - val_accuracy: 0.8515\n",
            "Epoch 4/100\n",
            "1688/1688 [==============================] - 1578s 935ms/step - loss: 0.2718 - accuracy: 0.9144 - val_loss: 0.4264 - val_accuracy: 0.8657\n",
            "Epoch 5/100\n",
            "1688/1688 [==============================] - 225s 133ms/step - loss: 0.2195 - accuracy: 0.9288 - val_loss: 0.4034 - val_accuracy: 0.8747\n",
            "Epoch 6/100\n",
            "1688/1688 [==============================] - 225s 133ms/step - loss: 0.1800 - accuracy: 0.9389 - val_loss: 0.4072 - val_accuracy: 0.8763\n",
            "Epoch 7/100\n",
            "1688/1688 [==============================] - 225s 133ms/step - loss: 0.1556 - accuracy: 0.9461 - val_loss: 0.4086 - val_accuracy: 0.8792\n",
            "Epoch 8/100\n",
            "1688/1688 [==============================] - 226s 134ms/step - loss: 0.1383 - accuracy: 0.9510 - val_loss: 0.3993 - val_accuracy: 0.8873\n",
            "Epoch 9/100\n",
            "1688/1688 [==============================] - 238s 141ms/step - loss: 0.1227 - accuracy: 0.9563 - val_loss: 0.4512 - val_accuracy: 0.8790\n",
            "Epoch 10/100\n",
            "1688/1688 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9580"
          ]
        }
      ],
      "source": [
        "for rnn, hidded_ac_fun, output_ac_fun, optimizer in product(rnn_models, hidded_activation_functions, output_activation_functions, optimizers):\n",
        "\n",
        "    check_point_name = f'{rnn}_{hidded_ac_fun}_{output_ac_fun}_{optimizer}.h5'\n",
        "\n",
        "    accuracy, history, model= rnn_model(\n",
        "        rnn_layer = rnn,\n",
        "        max_token = max_token,\n",
        "        input_dim = len(tokenizer.word_index) + 1 ,\n",
        "        embedding_matrix = embedding_matrix,\n",
        "        units = (128, 64, 32, 16),\n",
        "        epochs = 100,\n",
        "        hidden_activation = hidded_ac_fun,\n",
        "        output_activation = output_ac_fun,\n",
        "        optimizer = optimizer,\n",
        "        check_point_name = check_point_name,\n",
        "        use_es = True,\n",
        "        train_data = X_train_tokenized_pad,\n",
        "        test_data = X_test_tokenized_pad,\n",
        "        train_label = y_train_categorical,\n",
        "        test_label = y_test_categorical,\n",
        "        path_to_save_model = path\n",
        "    )\n",
        "    trained_model.loc[len(trained_model)] = [rnn, hidded_ac_fun, output_ac_fun, optimizer, accuracy, history, model, check_point_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQZ1DLFBrE1i"
      },
      "outputs": [],
      "source": [
        "df.head(24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_plot(model_history, rnn, hidded_ac_fun, output_ac_fun, optimizer, accuracy):\n",
        "    plt.title(f\"{rnn}-{hidded_ac_fun}-{output_ac_fun}-{optimizer}-{accuracy}\")\n",
        "    plt.plot(model_history.history['loss'], label='training loss')\n",
        "    plt.plot(model_history.history['val_loss'], label='validation loss')\n",
        "    plt.legend(['loss', 'val_loss'], loc='upper right')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_history, rnn, hidded_ac_fun, output_ac_fun, optimizer, accuracy in zip(\n",
        "    trained_model['history'], trained_model['RNN model'], trained_model['hiddedn activation function'], \n",
        "    trained_model['output activation function'], trained_model['optimizer'], trained_model['accuracy']):\n",
        "    \n",
        "    loss_plot(model_history, rnn, hidded_ac_fun, output_ac_fun, optimizer, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
